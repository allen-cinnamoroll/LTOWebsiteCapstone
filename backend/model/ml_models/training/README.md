# LTO Incident Case Status Prediction - ML Training

This directory contains the machine learning training pipeline for predicting incident case status based on incident characteristics.

## ğŸ¯ Purpose

The ML model predicts the **case status** (Pending, Ongoing, Solved, Closed) of traffic incidents based on various features like:
- Incident type
- Offense type
- Location (municipality, barangay, region, province)
- Temporal features (date, time, day of week)
- Stage of felony
- Geographic coordinates (lat/lng)

## ğŸ“ Updated Data Structure

The training pipeline now works with the **new incident data structure**:

### Key Fields:
- `blotterNo` - Unique incident identifier
- `dateCommited` - Date when incident occurred
- `caseStatus` - **Target variable** (Pending, Ongoing, Solved, Closed)
- `incidentType` - Type of incident
- `offenseType` - Classification of offense
- `vehiclePlateNo`, `vehicleMCPlateNo`, `vehicleChassisNo` - Vehicle identifiers
- `suspect`, `stageOfFelony`, `offense`, `narrative` - Case details
- `municipality`, `barangay`, `street`, `region`, `province` - Location
- `lat`, `lng` - Geographic coordinates

## ğŸš€ How to Use

### Step 1: Export Data from MongoDB

First, export the incident data from MongoDB to CSV format:

```bash
cd backend/scripts
node export_incidents_for_ml.cjs
```

This creates: `backend/data/raw/accidents_data.csv`

### Step 2: Train the Model

Navigate to the training directory and run the training script:

```bash
cd backend/model/ml_models/training
python train_models.py
```

### Step 3: Review Results

Training outputs will be saved to:
- `backend/model/ml_models/trained/` - Trained models
- `backend/logs/` - Training logs

## ğŸ“Š Model Components

### 1. Random Forest Classifier
- Predicts case status based on incident features
- Uses cross-validation for robust evaluation
- Provides feature importance analysis

### 2. Rule-Based System
- Prescriptive analytics for incident management
- Risk thresholds: high, medium, low
- Actionable recommendations for each risk level

## âš™ï¸ Configuration

Edit `model_config.yaml` to customize:

```yaml
features:
  categorical_features:
    - incidentType
    - offenseType
    - municipality
    - stageOfFelony
    - province
    - region
  numerical_features:
    - lat
    - lng
  target_feature: caseStatus
  date_feature: dateCommited
```

### Case Status Mapping:
```yaml
case_status_mapping:
  Pending: 1
  Ongoing: 2
  Solved: 3
  Closed: 4
```

## ğŸ“ˆ Model Evaluation Metrics

The training process reports:
- **Accuracy** - Overall prediction accuracy
- **Precision** - Positive prediction reliability
- **Recall** - True positive detection rate
- **F1-Score** - Harmonic mean of precision and recall
- **Confusion Matrix** - Detailed prediction breakdown
- **Feature Importance** - Most influential features

## ğŸ”§ Dependencies

```bash
pip install pandas numpy scikit-learn pyyaml joblib
```

## ğŸ“ Files

- `train_models.py` - Main training script
- `feature_engineering.py` - Feature extraction and preprocessing
- `model_config.yaml` - Training configuration
- `train_sarima_registrations.py` - SARIMA trainer for weekly registration forecasts
- `README.md` - This file

## ğŸ“‰ Time-Series Forecasting (SARIMA)

We now include a SARIMA training pipeline for vehicle registration forecasting. It uses the historical renewal dataset found at `backend/model/ml_models/mv registration training/DAVOR_data.csv` and produces a weekly time series model suitable for the Flask prediction APIs.

### How to Train the SARIMA Model

```bash
cd backend/model/ml_models/training
python train_sarima_registrations.py
```

This script:

1. Loads the renewal dataset, aggregates weekly counts, and splits the last 20% for evaluation.
2. Runs a lightweight grid search over SARIMA hyperparameters using AIC.
3. Evaluates the best candidate on the hold-out set (MAE, RMSE, MAPE).
4. Refits the best configuration on the full dataset and saves artifacts.

### Output Artifacts

Models and metadata are stored under `backend/model/ml_models/training/models/`:

- `sarima_registrations.pkl` â€“ Serialized SARIMAX results object (load with `joblib.load`).
- `sarima_registrations_metadata.json` â€“ Training metadata (orders, metrics, sample windows).

These files can be copied or referenced by any Flask microservice that needs registration forecasts (see `mv_registration_flask` for integration patterns).

## ğŸ“ Model Output

After training, the following files are created:

- `accident_rf_model.pkl` - Trained Random Forest model
- `accident_rule_system.pkl` - Rule-based prescriptive system
- `feature_encoders.pkl` - Label encoders for categorical features
- `scaler.pkl` - Standard scaler for numerical features
- `feature_columns.pkl` - List of feature columns
- `model_metadata.json` - Model configuration and metadata

## ğŸš¨ Troubleshooting

### Issue: "No data found"
**Solution:** Run the export script first to generate CSV data

### Issue: "KeyError: caseStatus"
**Solution:** Ensure your CSV has the `caseStatus` column

### Issue: "Too few samples"
**Solution:** Need at least 10-20 incidents per case status category

## ğŸ“ Support

For issues or questions, refer to the main project documentation.

